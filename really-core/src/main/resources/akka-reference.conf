#**
#* Copyright (C) 2014-2015 Really Inc. <http://really.io>
#**
really.core {
  akka {
    loggers = ["akka.event.slf4j.Slf4jLogger"]
    loglevel = INFO

    debug {
      receive = on
      lifecycle = on
      event-stream = on
    }
    actor {
      provider = "akka.cluster.ClusterActorRefProvider"
    }

    remote {
      netty.tcp {
        hostname = "127.0.0.1"
        port = 2551
      }
      log-remote-lifecycle-events = off
    }

    cluster {
      seed-nodes = [
        "akka.tcp://Really@127.0.0.1:2551"]
      min-nr-of-members = 1
      auto-down-unreachable-after = 10s
    }


    persistence.journal.plugin = "akka.persistence.journal.leveldb"
    persistence.journal.leveldb.dir = "target/journal"
    persistence.journal.leveldb.native = off
    persistence.snapshot-store.local.dir = "target/snapshots"

    log-dead-letters = 1000

    contrib.cluster.sharding {
      # The extension creates a top level actor with this name in top level user scope,
      # e.g. '/user/sharding'
      guardian-name = sharding
      # If the coordinator can't store state changes it will be stopped
      # and started again after this duration.
      coordinator-failure-backoff = 10 s
      # Start the coordinator singleton manager on members tagged with this role.
      # All members are used if undefined or empty.
      # ShardRegion actor is started in proxy only mode on nodes that are not tagged
      # with this role.
      role = ""
      # The ShardRegion retries registration and shard location requests to the
      # ShardCoordinator with this interval if it does not reply.
      retry-interval = 2 s
      # Maximum number of messages that are buffered by a ShardRegion actor.
      buffer-size = 100000
      # Timeout of the shard rebalancing process.
      handoff-timeout = 60 s
      # Rebalance check is performed periodically with this interval.
      rebalance-interval = 10 s
      # How often the coordinator saves persistent snapshots, which are
      # used to reduce recovery times
      snapshot-interval = 3600 s
      # Setting for the default shard allocation strategy
      least-shard-allocation-strategy {
        # Threshold of how large the difference between most and least number of
        # allocated shards must be to begin the rebalancing.
        rebalance-threshold = 10
        # The number of ongoing rebalancing processes is limited to this number.
        max-simultaneous-rebalance = 3
      }
    }

    extensions = ["akka.contrib.pattern.DistributedPubSubExtension"]

    # Settings for the DistributedPubSubExtension
    contrib.cluster.pub-sub {
      # Actor name of the mediator actor, /user/distributedPubSubMediator
      name = GorillaPubSub

      # Start the mediator on members tagged with this role.
      # All members are used if undefined or empty.
      role = ""

      # The routing logic to use for 'Send'
      # Possible values: random, round-robin, broadcast
      routing-logic = random

      # How often the DistributedPubSubMediator should send out gossip information
      gossip-interval = 1s

      # Removed entries are pruned after this duration
      removed-time-to-live = 120s

      # Maximum number of elements to transfer in one message when synchronizing the registries.
      # Next chunk will be transferred in next round of gossip.
      max-delta-elements = 3000
    }
  }
}